{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Черновики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "    .env\n",
      "    .gitignore\n",
      "    CLIP_finetuning_v3 (1).ipynb\n",
      "    example_files.txt\n",
      "    explore_errors.ipynb\n",
      "    finetuned_clip_model.pth\n",
      "    finetuned_clip_model_roc093_fixme.pth\n",
      "    finetuned_clip_model_roc099_fixme.pth\n",
      "    inference (5).ipynb\n",
      "    inference (7).ipynb\n",
      "    inference.ipynb\n",
      "    LICENSE\n",
      "    Makefile\n",
      "    prepare_data_for_finetuning.ipynb\n",
      "    pyproject.toml\n",
      "    README.md\n",
      "    requirements.txt\n",
      "    setup.py\n",
      "    test_environment.py\n",
      "    test_files.txt\n",
      "    tox.ini\n",
      "    __init__.py\n",
      "    data/\n",
      "        benchmarked.rar\n",
      "        external/\n",
      "            .gitkeep\n",
      "        processed/\n",
      "            .gitkeep\n",
      "    docs/\n",
      "        commands.rst\n",
      "        conf.py\n",
      "        getting-started.rst\n",
      "        index.rst\n",
      "        make.bat\n",
      "        Makefile\n",
      "    models/\n",
      "        .gitkeep\n",
      "        finetuned_clip_model_roc093.pth\n",
      "        finetuned_clip_model_roc099.pth\n",
      "        finetuned_clip_model_roc09997.pth\n",
      "        __pycache__/\n",
      "            evaluation.cpython-311.pyc\n",
      "    notebooks/\n",
      "        .gitkeep\n",
      "        Clip_finetuning_dataset_creation.ipynb\n",
      "        inference.ipynb\n",
      "        text_detection.ipynb\n",
      "        try_detect.ipynb\n",
      "    references/\n",
      "        .gitkeep\n",
      "    reports/\n",
      "        .gitkeep\n",
      "        figures/\n",
      "            .gitkeep\n",
      "    src/\n",
      "        train.py\n",
      "        __init__.py\n",
      "        data/\n",
      "            .gitkeep\n",
      "            crop_squares.py\n",
      "            data_for_finetuning.py\n",
      "            make_dataset.py\n",
      "            prediction.py\n",
      "            prepare_dataset.py\n",
      "            preprocessing.py\n",
      "            preprocess_labels.py\n",
      "            __init__.py\n",
      "            __pycache__/\n",
      "                crop_squares.cpython-311.pyc\n",
      "                data_for_finetuning.cpython-311.pyc\n",
      "                preprocessing.cpython-311.pyc\n",
      "                preprocess_labels.cpython-311.pyc\n",
      "                __init__.cpython-311.pyc\n",
      "        features/\n",
      "            .gitkeep\n",
      "            build_features.py\n",
      "            __init__.py\n",
      "        models/\n",
      "            .gitkeep\n",
      "            clip_finetune.py\n",
      "            evaluation.py\n",
      "            predict_model.py\n",
      "            train_model.py\n",
      "            __init__.py\n",
      "            __pycache__/\n",
      "                clip_finetune.cpython-311.pyc\n",
      "                evaluation.cpython-311.pyc\n",
      "                __init__.cpython-311.pyc\n",
      "        visualization/\n",
      "            .gitkeep\n",
      "            visualize.py\n",
      "            __init__.py\n",
      "            __pycache__/\n",
      "                visualize.cpython-311.pyc\n",
      "                __init__.cpython-311.pyc\n",
      "        __pycache__/\n",
      "            __init__.cpython-311.pyc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "\n",
    "def read_gitignore(gitignore_path):\n",
    "    ignored = []\n",
    "    if os.path.exists(gitignore_path):\n",
    "        with open(gitignore_path, 'r') as file:\n",
    "            ignored = [line.strip() for line in file.readlines() if line.strip() and not line.startswith('#')]\n",
    "    return ignored\n",
    "\n",
    "def print_directory_structure(start_path, exclude_dirs, exclude_files):\n",
    "    exclude_dirs = [os.path.normpath(os.path.join(start_path, ed)) for ed in exclude_dirs]  # Нормализуем пути\n",
    "    gitignore_path = os.path.join(start_path, '.gitignore')\n",
    "    ignored = read_gitignore(gitignore_path)\n",
    "    \n",
    "    for root, dirs, files in os.walk(start_path, topdown=True):\n",
    "        dirs[:] = [d for d in dirs if os.path.normpath(os.path.join(root, d)) not in exclude_dirs]\n",
    "        if '.git' in dirs:  # Явное исключение папки .git\n",
    "            dirs.remove('.git')\n",
    "\n",
    "        level = root.replace(start_path, '').count(os.sep)\n",
    "        indent = ' ' * 4 * level\n",
    "        print(f'{indent}{os.path.basename(root)}/')\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            relative_path = os.path.normpath(os.path.join(root, f)).replace(start_path, '').lstrip(os.sep)\n",
    "            if not any(fnmatch.fnmatch(relative_path, pattern) for pattern in ignored + exclude_files):\n",
    "                print(f'{subindent}{f}')\n",
    "\n",
    "start_path = '.'  # Исходный путь, с которого начинается обход\n",
    "exclude_dirs = ['data/raw', 'data/interim', 'data/benchmarked']  # Список папок для исключения\n",
    "exclude_files = []  # Список файлов для исключения будет заполнен на основе .gitignore\n",
    "print_directory_structure(start_path, exclude_dirs, exclude_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "# Функция для поиска и записи информации о функциях и комментариях\n",
    "def find_functions_and_comments(file_paths, output_file='functions_and_comments.txt'):\n",
    "    func_pattern = re.compile(r'def\\s+([a-zA-Z_\\u0400-\\u04FF][a-zA-Z0-9_\\u0400-\\u04FF]*)\\s*\\((.*?)\\):')\n",
    "    comment_pattern = re.compile(r'\"\"\"(.*?)\"\"\"', re.DOTALL)\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as out_f:\n",
    "        for path in file_paths:\n",
    "            if os.path.isfile(path) and path.endswith('.py'):\n",
    "                with open(path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                    functions = func_pattern.finditer(content)\n",
    "                    out_f.write(f'Path: {path}\\n')\n",
    "                    for func in functions:\n",
    "                        start_index = func.end()\n",
    "                        comment_match = comment_pattern.search(content, start_index)\n",
    "                        if comment_match:\n",
    "                            func_name = func.group(1)\n",
    "                            comment = comment_match.group(1).strip()\n",
    "                            out_f.write(f'Function: {func_name}\\nComment: {comment}\\n\\n')\n",
    "                    out_f.write(f'\\n\\n')\n",
    "                    \n",
    "\n",
    "# Пример использования\n",
    "file_paths = [\n",
    "    \"src/data/crop_squares.py\",\n",
    "    \"src/data/data_for_finetuning.py\",\n",
    "    \"src/data/prediction.py\",\n",
    "    \"src/data/prepare_dataset.py\",\n",
    "    \"src/data/preprocess_labels.py\",\n",
    "    \"src/data/preprocessing.py\",\n",
    "    \"src/models/clip_finetune.py\",\n",
    "    \"src/models/evaluation.py\",\n",
    "    \"src/train.py\"\n",
    "]\n",
    "find_functions_and_comments(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src/data/crop_squares.py: import numpy as np\n",
      "src/data/crop_squares.py: import matplotlib.pyplot as plt\n",
      "src/data/crop_squares.py: import cv2\n",
      "src/data/crop_squares.py: from copy import deepcopy\n",
      "src/data/crop_squares.py: from PIL import Image, ImageDraw\n",
      "src/data/crop_squares.py: from typing import Optional, Any, List\n",
      "src/data/crop_squares.py: import os\n",
      "src/data/data_for_finetuning.py: from PIL import Image\n",
      "src/data/data_for_finetuning.py: import json\n",
      "src/data/data_for_finetuning.py: import json\n",
      "src/data/prepare_dataset.py: import pandas as pd\n",
      "src/data/prepare_dataset.py: from torch.utils.data import Dataset, DataLoader\n",
      "src/data/prepare_dataset.py: from torchvision import transforms\n",
      "src/data/prepare_dataset.py: from PIL import Image\n",
      "src/data/prepare_dataset.py: import numpy as np\n",
      "src/data/prepare_dataset.py: import torch\n",
      "src/data/preprocess_labels.py: import easyocr\n",
      "src/data/preprocess_labels.py: import os\n",
      "src/data/preprocess_labels.py: from PIL import Image\n",
      "src/data/preprocessing.py: from PIL import Image\n",
      "src/data/preprocessing.py: import os\n",
      "src/data/preprocessing.py: from tqdm import tqdm\n",
      "src/data/preprocessing.py: from typing import Optional, Any, List\n",
      "src/models/clip_finetune.py: import torch\n",
      "src/models/clip_finetune.py: from torch import nn\n",
      "src/models/clip_finetune.py: import clip\n",
      "src/models/evaluation.py: import json\n",
      "src/models/evaluation.py: from math import sqrt\n",
      "src/models/evaluation.py: from typing import Optional, Any, List\n",
      "src/models/evaluation.py: import os\n",
      "src/models/evaluation.py: from tqdm import tqdm\n",
      "src/models/evaluation.py: from PIL import Image\n",
      "src/models/evaluation.py: import torch\n",
      "src/models/evaluation.py: from src.data.preprocessing import split_and_save_image\n",
      "src/models/evaluation.py: from src.data.preprocess_labels import recognize_digit, save_bottom_half\n",
      "src/models/evaluation.py: from src.models.clip_finetune import CLIPFineTuneModel\n",
      "src/models/evaluation.py: from src.data.crop_squares import save_squares, combine_functions_to_get_centers, calculate_median_coordinates\n",
      "src/models/evaluation.py: from src.visualization.visualize import display_comparison\n",
      "src/train.py: import torch\n",
      "src/train.py: from torch import optim, nn\n",
      "src/train.py: from .models.clip_finetune import CLIPFineTuneModel, загрузить_и_заморозить_CLIP\n",
      "src/train.py: from .data.prepare_dataset import CustomImageDataset\n"
     ]
    }
   ],
   "source": [
    "def extract_imports(file_path):\n",
    "    with open(file_path, \"r\", encoding='utf-8') as file:\n",
    "        # Проходим по каждой строке в файле\n",
    "        for line in file:\n",
    "            # Обрезаем пробельные символы с обеих сторон строки\n",
    "            stripped_line = line.strip()\n",
    "            # Проверяем, начинается ли строка с 'import' или 'from'\n",
    "            if stripped_line.startswith(\"import\") or stripped_line.startswith(\"from\"):\n",
    "                print(f\"{file_path}: {stripped_line}\")\n",
    "\n",
    "# Обходим все скрипты в списке и извлекаем строки с импортами\n",
    "for script in file_paths:\n",
    "    extract_imports(script)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
