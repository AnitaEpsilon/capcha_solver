{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fiv6qukkVLbc",
        "outputId": "cae5caf9-caa1-4a98-dee9-ce0f162b5a79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.13)\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.1.3\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-zwvngdyu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-zwvngdyu\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.1.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.16.0+cu121)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369497 sha256=8bc39d4899ea12d0e7d62ccde0f3746a2ad7bb01e37c20a0dc33ee71384b639c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dc6jivvz/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "Successfully installed clip-1.0\n"
          ]
        }
      ],
      "source": [
        "  ! pip install ftfy regex tqdm\n",
        "  ! pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vGij1IqrCz9"
      },
      "source": [
        "# New dataset creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "m4rXp-JwrCz_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "# Функция для проверки наличия файлов с картинками\n",
        "def check_image_files(folder_path):\n",
        "    image_path = os.path.join(folder_path, 'im.jpg')\n",
        "    correct_path = os.path.join(folder_path, 'correct.jpg')\n",
        "    \n",
        "    if os.path.exists(image_path) and os.path.exists(correct_path):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "# Путь к директории с папками\n",
        "directory = 'data/benchmarked'\n",
        "# Список всех папок в директории\n",
        "folders = [f for f in os.listdir(directory) if os.path.isdir(os.path.join(directory, f))]\n",
        "\n",
        "# Создаем CSV-файл для записи результатов\n",
        "with open('data/benchmarked/results.csv', mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Image 1', 'Image 2', 'Boolean'])\n",
        "\n",
        "    # Проходим по каждой папке\n",
        "    for i, folder in enumerate(folders):\n",
        "        # Получаем путь к текущей папке\n",
        "        folder_path = os.path.join(directory, folder)\n",
        "\n",
        "        # Проверяем наличие файлов с картинками\n",
        "        if check_image_files(folder_path):\n",
        "            # Создаем строки для таблицы, если файлы существуют\n",
        "            first_row = [os.path.join(folder_path, 'im.jpg'), os.path.join(folder_path, 'correct.jpg'), True]\n",
        "            writer.writerow(first_row)\n",
        "\n",
        "            next_folder = folders[i + 1] if i < len(folders) - 1 else None\n",
        "\n",
        "            if next_folder and check_image_files(next_folder):\n",
        "                next_folder_path = os.path.join(directory, next_folder)\n",
        "                second_row = [os.path.join(folder_path, 'im.jpg'), os.path.join(next_folder_path, 'correct.jpg'), False]\n",
        "                writer.writerow(second_row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI_uR_IYVrH_"
      },
      "source": [
        "# Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEX3IuVWmDLY",
        "outputId": "f7523689-4003-4ee7-f75d-bad43c31f6b6"
      },
      "outputs": [],
      "source": [
        "import clip\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Загрузка предварительно обученной модели CLIP\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "# Заморозка весов модели CLIP\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2jU347oRmIcb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import clip\n",
        "import torch\n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "\n",
        "class CLIPFineTuneModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Класс для настройки модели CLIP с добавлением линейного слоя для финетюнинга.\n",
        "\n",
        "    Атрибуты:\n",
        "    - clip_model (torch.nn.Module): предобученная модель CLIP.\n",
        "    - linear (torch.nn.Linear): линейный слой для трансформации признаков.\n",
        "    - cosine_similarity (torch.nn.CosineSimilarity): слой для вычисления косинусного сходства между векторами признаков.\n",
        "\n",
        "    Методы:\n",
        "    - forward(img1, img2): Проход вперед, который принимает пары изображений и возвращает оценку их сходства.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, clip_model):\n",
        "        \"\"\"\n",
        "        Инициализирует класс с предобученной моделью CLIP и добавляет линейный слой.\n",
        "\n",
        "        Параметры:\n",
        "        - clip_model (torch.nn.Module): предобученная модель CLIP.\n",
        "        \"\"\"\n",
        "        super(CLIPFineTuneModel, self).__init__()\n",
        "        self.clip_model = clip_model\n",
        "        self.linear = nn.Linear(512, 64)\n",
        "        self.cosine_similarity = nn.CosineSimilarity(dim=1)\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        \"\"\"\n",
        "        Выполняет проход вперед, принимая два изображения и вычисляя их сходство.\n",
        "\n",
        "        Параметры:\n",
        "        - img1 (torch.Tensor): тензор первого изображения.\n",
        "        - img2 (torch.Tensor): тензор второго изображения.\n",
        "\n",
        "        Выходные данные:\n",
        "        - similarity (torch.Tensor): тензор с оценками сходства изображений.\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            features1 = self.clip_model.encode_image(img1).to(dtype=torch.float32)\n",
        "            features2 = self.clip_model.encode_image(img2).to(dtype=torch.float32)\n",
        "\n",
        "        transformed_features1 = self.linear(features1).to(dtype=torch.float32)\n",
        "        transformed_features2 = self.linear(features2).to(dtype=torch.float32)\n",
        "        transformed_features1 = transformed_features1 / transformed_features1.norm(dim=-1, keepdim=True)\n",
        "        transformed_features2 = transformed_features2 / transformed_features2.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        similarity = self.cosine_similarity(transformed_features1, transformed_features2).unsqueeze(-1).to(dtype=torch.float32)\n",
        "        return similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sN6_Wwrcmm6L"
      },
      "outputs": [],
      "source": [
        "finetune_model = CLIPFineTuneModel(model).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JyXHrn05l2UL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Класс датасета для пар изображений с метками их соответствия.\n",
        "\n",
        "    Атрибуты:\n",
        "    - dataframe (pandas.DataFrame): DataFrame с путями к изображениям и метками соответствия.\n",
        "    - transform (callable, optional): Преобразование, применяемое к каждому изображению.\n",
        "    - base_path (str): Базовый путь к изображениям.\n",
        "\n",
        "    Методы:\n",
        "    - __len__(): Возвращает размер датасета.\n",
        "    - __getitem__(idx): Возвращает пару изображений и метку их соответствия по индексу.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataframe, transform=None, base_path='train_data2/benchmarked/'):\n",
        "        \"\"\"\n",
        "        Инициализирует датасет с указанным DataFrame, трансформацией и базовым путем.\n",
        "\n",
        "        Параметры:\n",
        "        - dataframe (pandas.DataFrame): DataFrame с данными.\n",
        "        - transform (callable, optional): Функция преобразования изображений. По умолчанию None.\n",
        "        - base_path (str): Базовый путь к изображениям. По умолчанию 'train_data2/benchmarked/'.\n",
        "        \"\"\"\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "        self.base_path = base_path\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Возвращает общее количество пар изображений в датасете.\n",
        "\n",
        "        Выходные данные:\n",
        "        - int: Количество пар изображений.\n",
        "        \"\"\"\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Возвращает пару изображений и метку их соответствия по указанному индексу.\n",
        "\n",
        "        Параметры:\n",
        "        - idx (int): Индекс пары изображений в датасете.\n",
        "\n",
        "        Выходные данные:\n",
        "        - tuple: Пара трансформированных изображений и метка соответствия (torch.Tensor, torch.Tensor, float).\n",
        "        \"\"\"\n",
        "        img1_path = self.base_path + self.dataframe.iloc[idx, 0]\n",
        "        img2_path = self.base_path + self.dataframe.iloc[idx, 1]\n",
        "        label = self.dataframe.iloc[idx, 2].astype(np.float32)\n",
        "\n",
        "        img1 = Image.open(img1_path).convert(\"RGB\")\n",
        "        img2 = Image.open(img2_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            img1 = self.transform(img1)\n",
        "            img1 = (img1 - torch.min(img1)) / (torch.max(img1) - torch.min(img1))\n",
        "            img2 = self.transform(img2)\n",
        "            img2 = (img2 - torch.min(img2)) / (torch.max(img2) - torch.min(img2))\n",
        "\n",
        "        return img1, img2, label\n",
        "\n",
        "\n",
        "dataframe = pd.read_csv('data/benchmarked/results.csv')\n",
        "dataset = CustomImageDataset(dataframe=dataframe.head(256), transform=preprocess, base_path='')\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "icVPcuwNl9R2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "def show_batch(dataloader):\n",
        "    \"\"\"\n",
        "    Отображает первый батч изображений из даталоудера.\n",
        "\n",
        "    Параметры:\n",
        "    - dataloader (DataLoader): загрузчик данных PyTorch, содержащий пары изображений и метки их соответствия.\n",
        "\n",
        "    Выходные данные:\n",
        "    - None. Функция отображает изображения из первого батча в dataloader, используя matplotlib.\n",
        "    \"\"\"\n",
        "    for img1, img2, labels in dataloader:\n",
        "        batch_size = img1.size(0)  # Получаем размер батча\n",
        "        if batch_size == 1:\n",
        "            fig, axs = plt.subplots(batch_size, 2, figsize=(10, 5 * batch_size))\n",
        "            axs = np.array([axs])  # Преобразуем axs в 2D массив для унификации доступа\n",
        "        else:\n",
        "            fig, axs = plt.subplots(batch_size, 2, figsize=(10, 5 * batch_size))\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            image1_pil = F.to_pil_image(img1[i].squeeze().cpu())\n",
        "            image2_pil = F.to_pil_image(img2[i].squeeze().cpu())\n",
        "\n",
        "            if batch_size == 1:\n",
        "                ax1, ax2 = axs[0]  # Для одномерного случая\n",
        "            else:\n",
        "                ax1, ax2 = axs[i]  # Для многомерного случая\n",
        "\n",
        "            ax1.imshow(image1_pil)\n",
        "            ax1.set_title(\"Image 1\")\n",
        "            ax1.axis('off')\n",
        "\n",
        "            ax2.imshow(image2_pil)\n",
        "            ax2.set_title(f\"Image 2 - {'True' if labels[i].item() == 1.0 else 'False'}\")\n",
        "            ax2.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        break  # Отображаем только первый батч"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vc6r6XximL4f",
        "outputId": "09412d51-64ae-4993-eb0b-8ed23dfc2f0b"
      },
      "outputs": [],
      "source": [
        "show_batch(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "m7eNIQ0hlbci",
        "outputId": "e0167ac8-98d8-4233-f60d-65e09edc690a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Training Loss: 0.0015384334630133317, Validation Loss: 0.00015935707657869594\n",
            "Epoch 2, Training Loss: 0.00010262169841250095, Validation Loss: 6.403548043939129e-05\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import clip\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.optim import Adam\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "dataframe = pd.read_csv('data/benchmarked/results.csv')\n",
        "\n",
        "# Коэффициент для определения индекса разделения данных (исключая последние 10%)\n",
        "split_ratio = 0.9\n",
        "train_ratio = 0.8\n",
        "\n",
        "# Вычисляем индекс для разделения данных, чтобы исключить последние 10%\n",
        "split_index = int(len(dataframe) * split_ratio)\n",
        "\n",
        "# Разделяем набор данных, чтобы исключить последние 10%\n",
        "dataframe = dataframe[:split_index]\n",
        "\n",
        "# Инициализируем набор данных с изменённым датафреймом\n",
        "dataset = CustomImageDataset(dataframe=dataframe, transform=preprocess, base_path='')\n",
        "\n",
        "# Разделяем набор данных на тренировочный и валидационный наборы\n",
        "train_size = int(train_ratio * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Загрузчики данных для тренировочного и валидационного наборов\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "def train_and_validate(model, train_dataloader, test_dataloader, criterion, optimizer, num_epochs=10):\n",
        "    \"\"\"\n",
        "    Обучает и валидирует модель на данных из даталоудеров.\n",
        "\n",
        "    Параметры:\n",
        "    - model (torch.nn.Module): модель для обучения.\n",
        "    - train_dataloader (DataLoader): загрузчик данных для обучения.\n",
        "    - test_dataloader (DataLoader): загрузчик данных для валидации.\n",
        "    - criterion (torch.nn.modules.loss): функция потерь.\n",
        "    - optimizer (torch.optim.Optimizer): оптимизатор.\n",
        "    - num_epochs (int, optional): количество эпох обучения. По умолчанию 10.\n",
        "\n",
        "    Выходные данные:\n",
        "    - None. Функция обучает модель, отображает график потерь на обучающем и валидационном наборах данных.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for img1, img2, labels in train_dataloader:\n",
        "            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device).float()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(img1, img2)\n",
        "            loss = criterion(outputs, labels.view(-1, 1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        train_losses.append(total_loss / len(train_dataloader))\n",
        "\n",
        "        model.eval()\n",
        "        total_test_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for img1, img2, labels in test_dataloader:\n",
        "                img1, img2, labels = img1.to(device), img2.to(device), labels.to(device).float()\n",
        "                outputs = model(img1, img2)\n",
        "                loss = criterion(outputs, labels.view(-1, 1))\n",
        "                total_test_loss += loss.item()\n",
        "        test_losses.append(total_test_loss / len(test_dataloader))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Training Loss: {train_losses[-1]}, Validation Loss: {test_losses[-1]}\")\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(test_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('MSE Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "optimizer = Adam(finetune_model.linear.parameters(), lr=1e-2)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "train_and_validate(finetune_model, train_dataloader, test_dataloader, criterion, optimizer, num_epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir('data/benchmarked\\\\186121\\\\')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aOwwgo-pH50",
        "outputId": "aa46e8c6-d7ea-4f15-e1da-b480157dd81d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7734138972809668\n"
          ]
        }
      ],
      "source": [
        "def calculate_accuracy(model, dataloader, threshold=0.6):\n",
        "    \"\"\"\n",
        "    Вычисляет точность модели на данных из даталоадера.\n",
        "\n",
        "    Параметры:\n",
        "    - model (torch.nn.Module): модель для оценки.\n",
        "    - dataloader (DataLoader): загрузчик данных для оценки.\n",
        "    - threshold (float, optional): порог для классификации между классами. По умолчанию 0.6.\n",
        "\n",
        "    Выходные данные:\n",
        "    - accuracy (float): точность модели на предоставленном наборе данных.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for img1, img2, labels in dataloader:\n",
        "            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
        "            outputs = model(img1, img2)\n",
        "            predictions = outputs > threshold\n",
        "            correct += (predictions.flatten().int() == labels.int()).sum().item()\n",
        "            total += labels.size(0)\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# Вычисляем accuracy на тестовом наборе данных\n",
        "test_accuracy = calculate_accuracy(finetune_model, test_dataloader, threshold=0.7)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "dfVsB967RnuO",
        "outputId": "a254c365-818c-4da9-e43c-766c75fda27f"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_curve, auc\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def get_model_predictions_and_labels(model: torch.nn.Module, dataloader: DataLoader, device: torch.device) -> tuple:\n",
        "    \"\"\"\n",
        "    Функция для получения предсказаний модели и истинных меток из даталоадера.\n",
        "\n",
        "    Аргументы:\n",
        "    - model: torch.nn.Module - модель для оценки\n",
        "    - dataloader: DataLoader - загрузчик данных\n",
        "    - device: torch.device - устройство, на котором происходит вычисление\n",
        "\n",
        "    Возвращает кортеж:\n",
        "    - predictions: List[float] - предсказания модели\n",
        "    - labels_list: List[int] - истинные метки\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    labels_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for img1, img2, labels in dataloader:\n",
        "            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
        "            outputs = model(img1, img2)\n",
        "            predictions.extend(outputs.flatten().cpu().numpy())\n",
        "            labels_list.extend(labels.cpu().numpy())\n",
        "\n",
        "    return predictions, labels_list\n",
        "\n",
        "def plot_roc_curve(model: torch.nn.Module, dataloader: DataLoader, device: torch.device):\n",
        "    \"\"\"\n",
        "    Функция для построения ROC-кривой для модели на данных из даталоадера.\n",
        "\n",
        "    Аргументы:\n",
        "    - model: torch.nn.Module - модель для оценки\n",
        "    - dataloader: DataLoader - загрузчик данных\n",
        "    - device: torch.device - устройство, на котором происходит вычисление\n",
        "    \"\"\"\n",
        "    predictions, labels = get_model_predictions_and_labels(model, dataloader, device)\n",
        "    fpr, tpr, thresholds = roc_curve(labels, predictions)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Кривая ROC (Receiver Operating Characteristic)')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "plot_roc_curve(finetune_model, test_dataloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hUuTkztrVHez"
      },
      "outputs": [],
      "source": [
        "# Путь для сохранения модели\n",
        "model_path = 'drive/MyDrive/Data_Science/other/capcha/finetuned_clip_model_delme.pth'\n",
        "optimizer_path = 'drive/MyDrive/Data_Science/other/capcha/optimizer_state_delme.pth'\n",
        "\n",
        "# Сохранение модели\n",
        "torch.save(finetune_model.state_dict(), model_path)\n",
        "\n",
        "# Сохранение состояния оптимизатора (по желанию)\n",
        "torch.save(optimizer.state_dict(), optimizer_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqqLhed7VrfY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i3-FKiM6I8o"
      },
      "source": [
        "# New dataset creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocadQOpH6Uuq",
        "outputId": "ee25ac6d-0ef9-43fa-a63e-a9e63e1c2259"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Архив успешно разархивирован в указанную папку!\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_filename = 'drive/MyDrive/Data_Science/other/capcha/benchmarked.zip'\n",
        "extract_folder = 'train_data2'\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "print('Архив успешно разархивирован в указанную папку!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfx2i-r9_HCO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "# Путь к директории с папками\n",
        "directory = 'train_data2/benchmarked'\n",
        "# Список всех папок в директории\n",
        "folders = [f for f in os.listdir(directory) if os.path.isdir(os.path.join(directory, f))]\n",
        "\n",
        "# Создаем CSV-файл для записи результатов\n",
        "with open('train_data2/benchmarked/results.csv', mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Image 1', 'Image 2', 'Boolean'])\n",
        "\n",
        "    # Проходим по каждой папке\n",
        "    for i, folder in enumerate(folders):\n",
        "        # Получаем путь к текущей папке\n",
        "        folder_path = os.path.join(directory, folder)\n",
        "\n",
        "        # Смотрим, есть ли следующая папка\n",
        "        next_folder = folders[i + 1] if i < len(folders) - 1 else None\n",
        "\n",
        "        # Создаем строки для таблицы, если это возможно\n",
        "        first_row = [os.path.join(folder_path, 'im.jpg'), os.path.join(folder_path, 'correct.jpg'), True]\n",
        "        writer.writerow(first_row)\n",
        "\n",
        "        if next_folder:\n",
        "            next_folder_path = os.path.join(directory, next_folder)\n",
        "            second_row = [os.path.join(folder_path, 'im.jpg'), os.path.join(next_folder_path, 'correct.jpg'), False]\n",
        "            writer.writerow(second_row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEJSzsYw-lM8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19ymUgW6Td0K"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdEg7PHvThjd",
        "outputId": "f9ec1df3-a939-4cd6-f404-2a45d1f8589b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity: 0.6541217565536499\n"
          ]
        }
      ],
      "source": [
        "import clip\n",
        "import torch\n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "\n",
        "# Загрузка предварительно обученной модели CLIP\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "# Инициализация модели надстройки\n",
        "finetune_model = CLIPFineTuneModel(model).to(device)\n",
        "\n",
        "# Путь к сохраненной модели\n",
        "model_path = 'finetuned_clip_model.pth'\n",
        "\n",
        "# Загрузка весов в модель\n",
        "finetune_model.load_state_dict(torch.load(model_path))\n",
        "finetune_model.eval()  # Переключение модели в режим оценки\n",
        "\n",
        "# Загрузка изображений\n",
        "img1_path = '183103_icon_1.jpg'\n",
        "img2_path = '183103_icon_2.jpg'\n",
        "img1 = Image.open(img1_path).convert(\"RGB\")\n",
        "img2 = Image.open(img2_path).convert(\"RGB\")\n",
        "\n",
        "# Преобразование изображений\n",
        "img1_processed = preprocess(img1).unsqueeze(0).to(device)\n",
        "img2_processed = preprocess(img2).unsqueeze(0).to(device)\n",
        "\n",
        "# Применение модели\n",
        "with torch.no_grad():\n",
        "    similarity = finetune_model(img1_processed, img2_processed)\n",
        "    print(f\"Similarity: {similarity.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89Yhk2p2ViYm",
        "outputId": "ce442d26-9c7b-4624-91b6-259a7ca3a95e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "2+2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l-G62j6Lmgl"
      },
      "source": [
        "# Inference test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF2z1__mLiTf",
        "outputId": "dfab50dd-e7f4-43eb-f1ba-4f4cc01c83ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.13)\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.1.3\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-37ls9nht\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-37ls9nht\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.1.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.16.0+cu121)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369497 sha256=78f87b7185107db6d411c0958958714b53aff747aa23ae353ff16d5e8e91d0f6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-399p3kxw/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "Successfully installed clip-1.0\n"
          ]
        }
      ],
      "source": [
        "! pip install ftfy regex tqdm\n",
        "! pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsMNCWNYLr1y",
        "outputId": "4760ac38-ff85-40ee-eb1f-bc3e083aa649"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=17UeoS3l5IEr7uCmLsjxjqxWpMnUEoWwQ\n",
            "From (redirected): https://drive.google.com/uc?id=17UeoS3l5IEr7uCmLsjxjqxWpMnUEoWwQ&confirm=t&uuid=e1888beb-db79-42c9-bd36-82bdf74adfb9\n",
            "To: /content/finetuned_clip_model_roc093.pth\n",
            "100% 354M/354M [00:05<00:00, 62.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 17UeoS3l5IEr7uCmLsjxjqxWpMnUEoWwQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "P01krPDBMfAK",
        "outputId": "1e51dc09-59ff-47d7-abc8-0437576503db"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "CLIPFineTuneModel.__init__() takes 1 positional argument but 2 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8f66eeefaa43>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ViT-B/32\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Инициализация модели надстройки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfinetune_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLIPFineTuneModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Путь к сохраненной модели\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_super_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             raise TypeError(f\"{type(self).__name__}.__init__() takes 1 positional argument but {len(args) + 1} were\"\n\u001b[0m\u001b[1;32m    465\u001b[0m                             \" given\")\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: CLIPFineTuneModel.__init__() takes 1 positional argument but 2 were given"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "# Инициализация модели надстройки\n",
        "finetune_model = CLIPFineTuneModel(model).to(device)\n",
        "\n",
        "# Путь к сохраненной модели\n",
        "model_path = 'finetuned_clip_model_roc093.pth'\n",
        "\n",
        "# Загрузка весов в модель\n",
        "#finetune_model.load_state_dict(torch.load(model_path))\n",
        "finetune_model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "finetune_model.eval()  # Переключение модели в режим оценки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "uV021u14Vo5d",
        "outputId": "4ce1fda0-db99-4f61-eeb9-16fea37741dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 338M/338M [00:06<00:00, 55.8MiB/s]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "CLIPFineTuneModel.__init__() takes 1 positional argument but 2 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-266c5e38c3de>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Инициализация и загрузка весов модели надстройки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mfinetune_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLIPFineTuneModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'finetuned_clip_model_roc093.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mfinetune_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_super_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             raise TypeError(f\"{type(self).__name__}.__init__() takes 1 positional argument but {len(args) + 1} were\"\n\u001b[0m\u001b[1;32m    465\u001b[0m                             \" given\")\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: CLIPFineTuneModel.__init__() takes 1 positional argument but 2 were given"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import clip\n",
        "from torch import nn\n",
        "\n",
        "# Загрузка модели CLIP и предобработка изображений\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "\n",
        "class CLIPFineTuneModel(nn.Module):\n",
        "    def init(self, clip_model):\n",
        "        super(CLIPFineTuneModel, self).init()\n",
        "        self.clip_model = clip_model\n",
        "        self.linear = nn.Linear(512, 64)  # Предполагается, что размерность вектора признаков CLIP - 512\n",
        "        self.cosine_similarity = nn.CosineSimilarity(dim=1)\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        with torch.no_grad():\n",
        "            features1 = self.clip_model.encode_image(img1).to(dtype=torch.float32)\n",
        "            features2 = self.clip_model.encode_image(img2).to(dtype=torch.float32)\n",
        "\n",
        "        transformed_features1 = self.linear(features1).to(dtype=torch.float32)\n",
        "        transformed_features2 = self.linear(features2).to(dtype=torch.float32)\n",
        "        transformed_features1 = transformed_features1 / transformed_features1.norm(dim=-1, keepdim=True)\n",
        "        transformed_features2 = transformed_features2 / transformed_features2.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        similarity = self.cosine_similarity(transformed_features1, transformed_features2).unsqueeze(-1).to(dtype=torch.float32)\n",
        "\n",
        "        return similarity\n",
        "\n",
        "\n",
        "# Инициализация и загрузка весов модели надстройки\n",
        "finetune_model = CLIPFineTuneModel(clip_model).to(device)\n",
        "model_path = 'finetuned_clip_model_roc093.pth'\n",
        "finetune_model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "finetune_model.eval()\n",
        "\n",
        "def get_image_features(image_path, model, preprocess):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image_processed = preprocess(image).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        features = model.encode_image(image_processed).to(dtype=torch.float32)\n",
        "    return features, image\n",
        "\n",
        "def compare_images(base_image_folder, compare_image_folder, digit, finetune_model, preprocess, visualize=False):\n",
        "    base_image_path = os.path.join(base_image_folder, \"im.jpg\")\n",
        "    base_features, base_image = get_image_features(base_image_path, clip_model, preprocess)\n",
        "\n",
        "    max_similarity = -1\n",
        "    max_similarity_index = -1\n",
        "\n",
        "    for i in range(1, 6):\n",
        "        compare_image_path = os.path.join(compare_image_folder, f\"x_{i}\", f\"{digit}.jpg\")\n",
        "        try:\n",
        "            compare_features, compare_image = get_image_features(compare_image_path, clip_model, preprocess)\n",
        "            # Использование модели надстройки для сравнения\n",
        "            similarity = finetune_model(base_features, compare_features).cpu().numpy()\n",
        "            if similarity > max_similarity:\n",
        "                max_similarity = similarity\n",
        "                max_similarity_index = i\n",
        "            if visualize:\n",
        "                # Функция display_comparison не определена в данном примере\n",
        "                display_comparison(base_image, compare_image, similarity, i)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Файл {compare_image_path} не найден.\")\n",
        "\n",
        "    return max_similarity_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "it8-ALODL5Fo"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Пример вызова функции compare_images\n",
        "base_image_folder = '/path/to/base/image/folder'\n",
        "compare_image_folder = '/path/to/compare/image/folder'\n",
        "digit = '1'  # Пример цифры\n",
        "max_similarity_index = compare_images(base_image_folder, compare_image_folder, digit, finetune_model, preprocess, visualize=True)\n",
        "print(f\"Наибольшая схожесть в папке: x_{max_similarity_index}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
